# -*- coding: utf-8 -*-
"""OPE Testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tf0Mqhy04t-t9zxuUq6F0j6dC01Tn5Ej
"""

import pickle
p = "/content/rmab_sequences.pkl"
with open(p,"rb") as f:
    d = pickle.load(f)
print("state dim:", len(d["state_cols"]))
print("n trajectories:", len(d["sequences"]))

!pip install lightgbm

import joblib, numpy as np
m = joblib.load("/content/behavior_model_lgbm_statecols_ISO.pkl")
print("behavior.classes_:", getattr(m, "classes_", None))
import numpy as np
probs = np.load("/content/behavior_propensity_probs_statecols.npy", allow_pickle=False)
print("propensities shape:", probs.shape)

import json
print(json.load(open("/content/ope_crossfit_summary.json")))
print(json.load(open("/content/policy_mix_selected_summary.json")))

import joblib, json, numpy as np, pandas as pd
from scipy.special import softmax
bundle = joblib.load("/content/policy_bundle.pkl")
state_cols = bundle["state_cols"]
behavior = bundle["models"]["behavior"]
q_models = bundle["models"]["q_models"]
S_test = np.zeros(len(state_cols))
X = pd.DataFrame([S_test], columns=state_cols).fillna(0.0)
b = behavior.predict_proba(X)[0]
actions = sorted(list(q_models.keys()))
q = np.array([q_models[a].predict(X.values)[0] for a in actions])
pi = softmax(q / 0.25)
pi_mix = 0.8*b + 0.2*pi
print("pi_mix:", pi_mix)

import json
cfg = json.load(open("/content/policy_mix_selected_summary.json"))
wis = cfg["wis_mean"]
ci_low, ci_high = cfg["wis_ci_low"], cfg["wis_ci_high"]
beh = cfg["behavior_value"]
uplift = wis - beh
uplift_ci_low = ci_low - beh
uplift_ci_high = ci_high - beh
print(f"WIS = {wis:.4f}  CI=[{ci_low:.4f},{ci_high:.4f}]")
print(f"Behavior (on-policy) = {beh:.4f}")
print(f"Uplift = {uplift:.4f}  CI=[{uplift_ci_low:.4f},{uplift_ci_high:.4f}]")
print(f"Relative uplift = {100*(uplift/beh):.2f}%")

import pandas as pd
rec = pd.read_csv("/content/ope_crossfit_per_traj.csv")

top_w = rec.sort_values("w_prod", ascending=False).head(20)
print("Top 20 trajectories by w_prod:\n", top_w[["key","fold","len","w_prod","final_rho","dr_noncum","dr_capped_cum"]])

top_rho = rec.sort_values("final_rho", ascending=False).head(20)
print("\nTop 20 trajectories by final_rho:\n", top_rho[["key","fold","len","w_prod","final_rho","dr_noncum","dr_capped_cum"]])

import numpy as np, matplotlib.pyplot as plt, pandas as pd
rec = pd.read_csv("/content/ope_crossfit_per_traj.csv")
w = rec["w_prod"].values
plt.figure(figsize=(6,3))
plt.hist(np.log1p(w), bins=200)
plt.title("log1p trajectory product weights (all)")
plt.show()

plt.figure(figsize=(6,3))
plt.hist(np.log1p(w), bins=200)
plt.xlim(0,8)
plt.title("log1p trajectory product weights (zoom xlim 0-8)")
plt.show()

plt.figure(figsize=(6,4))
plt.scatter(np.log1p(rec["w_prod"].values), rec["disc_return"].values, s=8, alpha=0.4)
plt.xlabel("log1p(w_prod)")
plt.ylabel("discounted return")
plt.title("w_prod vs discounted return (per-traj)")
plt.show()

from sklearn.calibration import calibration_curve
import joblib, numpy as np, pandas as pd
cal_iso = joblib.load("/content/behavior_model_lgbm_statecols_ISO.pkl")

df = pd.read_csv("/content/final_traj_clean_training_heart_v2_sorted_imputed.csv", low_memory=False)
sample = df.sample(n=20000, random_state=42)
X = sample[bundle["state_cols"]].apply(pd.to_numeric, errors='coerce').fillna(0.0)
y = sample["action_mapped"].astype(int)
probs = cal_iso.predict_proba(X)

prob_pos = probs[:,0]
frac_pos, mean_pred = calibration_curve((y==0).astype(int), prob_pos, n_bins=10)
print("Calibration curve (action 0):")
print(list(zip(mean_pred, frac_pos)))

import pickle, joblib, numpy as np, pandas as pd
bundle = joblib.load("/content/policy_bundle.pkl")
state_cols = bundle["state_cols"]
behavior = bundle["models"]["behavior"]
q_models = bundle["models"]["q_models"]

df = pd.read_csv("/content/final_traj_clean_training_heart_v2_sorted_imputed.csv", low_memory=False)

rows = df.sample(5, random_state=42)
for _, r in rows.iterrows():
    S = r[state_cols].astype(float).fillna(0.0).values
    X = pd.DataFrame([S], columns=state_cols)
    b = behavior.predict_proba(X)[0]
    actions = sorted(list(q_models.keys()))
    q = np.array([q_models[a].predict(X.values)[0] for a in actions])
    from scipy.special import softmax
    pi = softmax(q/0.25)
    pi_mix = 0.8*b + 0.2*pi
    print("orig hadm,aug,timestep:", (r.hadm_id, r.aug_id, r.timestep))
    print("b:", b, "\nq:", q, "\npi_mix:", pi_mix)
    print("-"*40)

"""***Debugging***"""

import pickle, joblib, numpy as np, pandas as pd
from scipy.special import softmax


sequences = pickle.load(open("/content/rmab_sequences.pkl", "rb"))["sequences"]
bundle = joblib.load("/content/policy_bundle.pkl")

behavior = bundle["models"]["behavior"]
q_models = bundle["models"]["q_models"]
state_cols = bundle["state_cols"]


k_key = "(168931, 1)"

seq = sequences[eval(k_key)]
S = seq["S"]
A = np.array(seq["A"], int)
R = np.array(seq["R"], float)

actions = sorted(q_models.keys())

print("Trajectory length:", len(A))
print("-"*60)

for t in range(len(A)):
    X = pd.DataFrame([S[t]], columns=state_cols).fillna(0.0)

    b = behavior.predict_proba(X)[0]
    q = np.array([q_models[a].predict(X.values)[0] for a in actions])
    pi = softmax(q / 0.25)

    a = A[t]
    b_sel = max(b[a], 1e-12)
    pi_sel = max(pi[a], 1e-12)
    ratio = pi_sel / b_sel

    print(
        f"t={t:2d} | a={a} | "
        f"b_sel={b_sel:.2e} | pi_sel={pi_sel:.2e} | "
        f"ratio={ratio:.2f} | q={q}"
    )

import pickle, joblib, numpy as np, pandas as pd
from scipy.special import softmax

sequences = pickle.load(open("/content/rmab_sequences.pkl", "rb"))["sequences"]
bundle = joblib.load("/content/policy_bundle.pkl")

behavior = bundle["models"]["behavior"]
q_models = bundle["models"]["q_models"]
state_cols = bundle["state_cols"]
actions = sorted(q_models.keys())

GAMMA = 0.95

def wis_for_cfg(temp=0.25, alpha=0.2, tau=0.0, clip=3.0):
    weights = []
    returns = []

    for seq in sequences.values():
        S = seq["S"]
        A = np.array(seq["A"], int)
        R = np.array(seq["R"], float)

        X = pd.DataFrame(S, columns=state_cols).fillna(0.0)
        b = behavior.predict_proba(X)                    # (T,K)
        q = np.vstack([q_models[a].predict(X.values) for a in actions]).T
        pi = softmax(q / temp, axis=1)

        # support truncation
        if tau > 0:
            mask = b < tau
            pi = np.where(mask, 0.0, pi)
            s = pi.sum(1, keepdims=True)
            pi = np.where(s > 0, pi/s, b)

        pi_mix = (1 - alpha) * b + alpha * pi

        idx = np.arange(len(A))
        b_sel = np.maximum(b[idx, A], 1e-12)
        pi_sel = np.maximum(pi_mix[idx, A], 1e-12)

        ratio = np.clip(pi_sel / b_sel, 0.0, clip)
        weights.append(np.prod(ratio))
        returns.append((GAMMA ** np.arange(len(R)) * R).sum())

    w = np.array(weights)
    r = np.array(returns)

    wis = (w * r).sum() / (w.sum() + 1e-12)
    ess = (w.sum() ** 2) / (np.sum(w ** 2) + 1e-12)

    return wis, ess

configs = [
    dict(temp=0.25, alpha=0.2, tau=0.0, clip=3.0),
    dict(temp=0.25, alpha=0.4, tau=0.01, clip=3.0),
    dict(temp=0.25, alpha=0.4, tau=0.01, clip=2.0),
    dict(temp=0.25, alpha=0.6, tau=0.01, clip=1.5),
]

for cfg in configs:
    w, e = wis_for_cfg(**cfg)
    print(cfg, "→ WIS:", round(w, 3), "ESS:", round(e, 1))

import pandas as pd

df = pd.read_csv("/content/final_traj_clean_training_heart_v2_sorted_imputed.csv", low_memory=False)

# how many augmentations per patient?
aug_counts = (
    df.groupby(["hadm_id", "aug_id"])
      .size()
      .groupby("hadm_id")
      .count()
      .sort_values(ascending=False)
)

print("Top hadm_ids by number of augmentations:")
print(aug_counts.head(20))


h = 168931
sub = df[df.hadm_id == h].sort_values(["aug_id", "timestep"])
print(sub.head(40))

import pickle, numpy as np, pandas as pd

sequences = pickle.load(open("/content/rmab_sequences.pkl","rb"))["sequences"]

# Choosing hadm to inspect from previous output
hid = 168931
# Collecting S,A,R per aug

augs = sorted([k for k in sequences.keys() if k[0]==hid])
print("augs:", augs)
for k in augs:
    seq = sequences[k]
    S = np.asarray(seq["S"])
    A = np.asarray(seq["A"])
    R = np.asarray(seq["R"])
    print(k, "shapes:", S.shape, A.shape, R.shape)


from itertools import combinations
for k1, k2 in combinations(augs,2):
    s1, s2 = sequences[k1]["S"], sequences[k2]["S"]
    a1, a2 = sequences[k1]["A"], sequences[k2]["A"]
    r1, r2 = sequences[k1]["R"], sequences[k2]["R"]
    same = (np.allclose(np.asarray(s1), np.asarray(s2)) and
            np.array_equal(np.asarray(a1), np.asarray(a2)) and
            np.allclose(np.asarray(r1), np.asarray(r2)))
    print(f"{k1} vs {k2} identical? {same}")



"""##**Stability Analysis & OPE Diagnostics**

"""

# Run once
import json, pickle, joblib, numpy as np, pandas as pd
from pathlib import Path
from scipy.special import softmax

BASE = Path("/content")
assert BASE.exists()


RMAB_PKL = BASE / "rmab_sequences.pkl"
CLEAN_CSV = BASE / "final_traj_clean_training_heart_v2_sorted_imputed.csv"
BHV_ISO_PKL = BASE / "behavior_model_lgbm_statecols_ISO.pkl"
BHV_PROBS = BASE / "behavior_propensity_probs_statecols.npy"
Q_MODELS_PKL = BASE / "q_models_fqe_strong.pkl"

print("Files present:")
for p in (RMAB_PKL, CLEAN_CSV, BHV_ISO_PKL, BHV_PROBS, Q_MODELS_PKL):
    print(" -", p.name, ":", "exists" if p.exists() else "MISSING")

with open(RMAB_PKL, "rb") as f:
    data = pickle.load(f)
state_cols = data["state_cols"]
sequences = data["sequences"]

print("state dim:", len(state_cols))
print("n trajectories:", len(sequences))


sample_key = next(iter(sequences))
S = sequences[sample_key]["S"]
A = sequences[sample_key]["A"]
R = sequences[sample_key]["R"]
print("sample shapes:", S.shape, A.shape, R.shape)

behavior = joblib.load(BHV_ISO_PKL)
probs = np.load(str(BHV_PROBS), allow_pickle=False)
print("behavior.classes_:", getattr(behavior, "classes_", None))
print("propensities shape:", probs.shape)

# Finding hadm_ids with many augmentations

df = pd.read_csv(CLEAN_CSV, low_memory=False)
counts = df.groupby("hadm_id")["aug_id"].nunique().sort_values(ascending=False).head(30)
print("Top hadm augment counts:\n", counts)


hid = 168931
grouped = df[df.hadm_id==hid].sort_values(["aug_id","timestep"])
print("augs:", sorted(grouped.aug_id.unique()))
for aug in sorted(grouped.aug_id.unique()):
    sub = grouped[grouped.aug_id==aug].sort_values("timestep")
    Scols = state_cols
    Sarr = sub[Scols].to_numpy()
    Aarr = sub["action_mapped"].to_numpy()
    Rarr = sub["reward"].to_numpy() if "reward" in sub.columns else None
    print((hid,aug), "shapes:", Sarr.shape, Aarr.shape, Rarr.shape if Rarr is not None else None)


augs = sorted(grouped.aug_id.unique())
arrays = []
for aug in augs:
    sub = grouped[grouped.aug_id==aug].sort_values("timestep")
    arrays.append((sub[state_cols].to_numpy(), sub["action_mapped"].to_numpy(),
                   sub["reward"].to_numpy() if "reward" in sub.columns else None))
for i in range(len(augs)):
    for j in range(i+1, len(augs)):
        sameS = np.array_equal(arrays[i][0], arrays[j][0])
        sameA = np.array_equal(arrays[i][1], arrays[j][1])
        sameR = True if (arrays[i][2] is None or arrays[j][2] is None) else np.array_equal(arrays[i][2], arrays[j][2])
        print(f"({hid},{augs[i]}) vs ({hid},{augs[j]}) identical? S:{sameS} A:{sameA} R:{sameR}")

"""***Dedupe***"""

import pickle, joblib, numpy as np, pandas as pd, time
from collections import Counter
from scipy.special import softmax


RMAB_PKL = "/content/rmab_sequences.pkl"
BUNDLE_PKL = "/content/policy_bundle.pkl"
CLEAN_CSV = "/content/final_traj_clean_training_heart_v2_sorted_imputed.csv"

print("Loading files...")
sequences = pickle.load(open(RMAB_PKL, "rb"))["sequences"]
bundle = joblib.load(BUNDLE_PKL)
behavior = bundle["models"]["behavior"]
q_models = bundle["models"]["q_models"]
state_cols = bundle["state_cols"]
actions = sorted(list(q_models.keys()))
print("n_sequences (orig):", len(sequences))


GAMMA = 0.95

def compute_wis_ess(seq_dict, temp=0.25, alpha=0.2, tau=0.0, clip=3.0):
    weights = []
    returns = []
    for k, seq in seq_dict.items():
        S = seq["S"]
        A = np.array(seq["A"], int)
        R = np.array(seq["R"], float)
        X = pd.DataFrame(S, columns=state_cols).fillna(0.0)
        b = behavior.predict_proba(X)    # (T,K)
        q = np.vstack([q_models[a].predict(X.values) for a in actions]).T
        pi = softmax(q / temp, axis=1)
        if tau > 0:
            mask = b < tau
            pi = np.where(mask, 0.0, pi)
            s = pi.sum(1, keepdims=True)
            pi = np.where(s>0, pi/s, b)
        pi_mix = (1.0 - alpha) * b + alpha * pi
        idx = np.arange(len(A))
        b_sel = np.maximum(b[idx, A], 1e-12)
        pi_sel = np.maximum(pi_mix[idx, A], 1e-12)
        ratio = np.clip(pi_sel / b_sel, 0.0, clip)
        weights.append(float(np.prod(ratio)))
        returns.append(float((GAMMA ** np.arange(len(R)) * R).sum()))
    w = np.array(weights, dtype=float)
    r = np.array(returns, dtype=float)
    wis = float((w * r).sum() / (w.sum() + 1e-12))
    ess = float((w.sum() ** 2) / (np.sum(w ** 2) + 1e-12)) if w.size>0 else 0.0
    behavior_value = float(r.mean())
    return wis, ess, behavior_value, w, r


chosen = {}
for (hid, aug) in sequences.keys():
    if hid not in chosen or aug < chosen[hid][0]:
        chosen[hid] = (aug, sequences[(hid, aug)])
seq_dedup = { (hid, aug): seq for hid,(aug,seq) in chosen.items() }
print("n_sequences (dedup):", len(seq_dedup))


grid = [
    {"temp":0.25, "alpha":0.2, "tau":0.0, "clip":3.0},
    {"temp":0.25, "alpha":0.4, "tau":0.01, "clip":3.0},
    {"temp":0.25, "alpha":0.4, "tau":0.01, "clip":2.0},
    {"temp":0.25, "alpha":0.6, "tau":0.01, "clip":1.5},
]

rows = []
t0 = time.time()
for cfg in grid:
    wis_o, ess_o, beh_o, w_o, r_o = compute_wis_ess(sequences, **cfg)
    wis_d, ess_d, beh_d, w_d, r_d = compute_wis_ess(seq_dedup, **cfg)
    rows.append({
        **cfg,
        "wis_orig": wis_o, "ess_orig": ess_o,
        "wis_dedup": wis_d, "ess_dedup": ess_d,
        "behavior_orig": beh_o, "behavior_dedup": beh_d,
        "n_orig": len(sequences), "n_dedup": len(seq_dedup)
    })
    print(cfg, "-> orig(WIS,ESS)=", round(wis_o,4), round(ess_o,1),
          "dedup(WIS,ESS)=", round(wis_d,4), round(ess_d,1))
print("Done in", round(time.time()-t0,1), "s")


df_res = pd.DataFrame(rows)
out_csv = "/content/wis_dedup_results.csv"
df_res.to_csv(out_csv, index=False)
print("Saved results to", out_csv)
print(df_res)


print("\nTop 10 trajectories by w_prod (orig):")
wprod = w_o if 'w_o' in locals() else None


keys = list(sequences.keys())
df_off = pd.DataFrame({
    "key": [str(k) for k in keys],
    "w_prod": w_o,
    "disc_return": r_o
})
print(df_off.sort_values("w_prod", ascending=False).head(10))

grid = [
  {"temp":0.25, "alpha":0.22, "tau":0.01, "clip":3.0},
  {"temp":0.25, "alpha":0.25, "tau":0.01, "clip":3.0},
  {"temp":0.25, "alpha":0.30, "tau":0.01, "clip":3.0},
  {"temp":0.25, "alpha":0.30, "tau":0.01, "clip":2.5},
  {"temp":0.25, "alpha":0.35, "tau":0.01, "clip":2.5},
]
# compute wis,ess on seq_dedup (using compute_wis_ess function from before)

for cfg in grid:
    wis, ess, beh, *_ = compute_wis_ess(seq_dedup, **cfg)
    print(cfg, "-> WIS:", round(wis,4), "ESS:", int(ess), "behavior:", round(beh,4))

import pickle, joblib, numpy as np, pandas as pd, time
from scipy.special import softmax
from collections import Counter


RMAB_PKL = "/content/rmab_sequences.pkl"
BUNDLE_PKL = "/content/policy_bundle.pkl"

print("Loading...")
sequences = pickle.load(open(RMAB_PKL, "rb"))["sequences"]
bundle = joblib.load(BUNDLE_PKL)
behavior = bundle["models"]["behavior"]
q_models = bundle["models"]["q_models"]
state_cols = bundle["state_cols"]
actions = sorted(list(q_models.keys()))

# Building deduped sequences

chosen = {}
for (hid, aug) in sequences.keys():
    if hid not in chosen or aug < chosen[hid][0]:
        chosen[hid] = (aug, sequences[(hid, aug)])
seq_dedup = { (hid, aug): seq for hid,(aug,seq) in chosen.items() }
print("n orig:", len(sequences), "n dedup:", len(seq_dedup))

# Chosen config -- FINAL

CFG = {"temp":0.25, "alpha":0.30, "tau":0.01, "clip":2.5}
GAMMA = 0.95

# Computing per-traj w_prod and disc_return
keys = list(seq_dedup.keys())
W = np.zeros(len(keys), dtype=float)
R = np.zeros(len(keys), dtype=float)

for i,k in enumerate(keys):
    seq = seq_dedup[k]
    S = seq["S"]
    A = np.array(seq["A"], int)
    RR = np.array(seq["R"], float)
    X = pd.DataFrame(S, columns=state_cols).fillna(0.0)
    b = behavior.predict_proba(X)
    q = np.vstack([q_models[a].predict(X.values) for a in actions]).T
    pi = softmax(q / CFG["temp"], axis=1)
    if CFG["tau"] > 0:
        mask = b < CFG["tau"]
        pi = np.where(mask, 0.0, pi)
        s = pi.sum(1, keepdims=True)
        pi = np.where(s>0, pi/s, b)
    pi_mix = (1.0 - CFG["alpha"]) * b + CFG["alpha"] * pi
    idx = np.arange(len(A))
    b_sel = np.maximum(b[idx, A], 1e-12)
    pi_sel = np.maximum(pi_mix[idx, A], 1e-12)
    ratio = np.clip(pi_sel / b_sel, 0.0, CFG["clip"])
    W[i] = float(np.prod(ratio))
    R[i] = float((GAMMA ** np.arange(len(RR)) * RR).sum())

# Quick check

print("Sample W (head):", W[:8])
print("Sample R (head):", R[:8])

# Computing point estimate (WIS)

V_wis = (W * R).sum() / (W.sum() + 1e-12)
ess = (W.sum()**2) / (np.sum(W**2) + 1e-12)
print("\nPoint estimate (WIS):", V_wis, "ESS:", ess)

# Bootstrap CI

B = 1000
rng = np.random.default_rng(42)
bs_vals = np.empty(B)
n = len(W)
t0 = time.time()
for b_i in range(B):
    idx = rng.integers(0, n, n)
    w_s = W[idx]; r_s = R[idx]
    bs_vals[b_i] = (w_s * r_s).sum() / (w_s.sum() + 1e-12)
ci_low, ci_high = np.percentile(bs_vals, [2.5, 97.5])
print(f"Bootstrap {B} CI for WIS: [{ci_low:.4f}, {ci_high:.4f}] (mean {bs_vals.mean():.4f})")
print("Elapsed:", round(time.time()-t0,1), "s")

# Saving results

out = {"cfg":CFG, "wis": float(V_wis), "ess": float(ess), "ci":[float(ci_low), float(ci_high)], "n_dedup": n}
pd.DataFrame([out]).to_csv("/content/wis_chosen_bootstrap.csv", index=False)
print("Saved /content/wis_chosen_bootstrap.csv")

"""## **Plots and Insights**"""

import matplotlib.pyplot as plt
import numpy as np



plt.figure(figsize=(6,4))
plt.hist(np.log1p(W), bins=60)
plt.xlabel("log(1 + trajectory weight)")
plt.ylabel("Count")
plt.title("Importance Weight Distribution (Deduplicated)")
plt.grid(True)
plt.show()

behavior = 3.736483
wis = 3.9445517
ci_low, ci_high = 3.6513, 4.2192

plt.figure(figsize=(5,4))
plt.bar(["Behavior", "Target Policy"], [behavior, wis])
plt.errorbar(["Target Policy"], [wis],
             yerr=[[wis - ci_low], [ci_high - wis]],
             fmt="none", capsize=8)

plt.ylabel("Estimated Discounted Return")
plt.title("Off-Policy Evaluation (WIS with 95% CI)")
plt.grid(True, axis="y")
plt.show()

import pandas as pd

df_top = pd.DataFrame({
    "traj_key": list(seq_dedup.keys()),
    "weight": W,
    "return": R
}).sort_values("weight", ascending=False).head(10)

df_top

import numpy as np, pandas as pd, matplotlib.pyplot as plt
from scipy.stats import gaussian_kde



# 1) Weight histogram
plt.figure(figsize=(7,4))
vals = np.log1p(W)
plt.hist(vals, bins=60)
plt.xlabel("log(1 + trajectory weight)")
plt.ylabel("Count")
plt.title("Importance Weight Distribution (deduped)")
plt.grid(True, alpha=0.3)
plt.xlim(0, 4.5)
plt.show()

# 2) Cumulative share of weight (how many trajectories carry most weight)

sorted_idx = np.argsort(W)[::-1]
cumw = np.cumsum(W[sorted_idx]) / (W.sum() + 1e-12)
pct_traj = np.arange(1, len(W)+1) / len(W) * 100

plt.figure(figsize=(6,4))
plt.plot(pct_traj, cumw*100, lw=2)
plt.axhline(50, color='C1', linestyle='--', label='50% weight')
plt.axhline(90, color='C2', linestyle='--', label='90% weight')
plt.xlabel("Top x% of trajectories (by weight)")
plt.ylabel("Cumulative weight (%)")
plt.title("Cumulative Weight Contribution")
plt.legend()
plt.grid(True, alpha=0.3)
plt.xlim(0,100)
plt.ylim(0,100)
plt.show()

# No. of trajectories cover 50% and 90%

n50 = np.searchsorted(cumw, 0.50) + 1
n90 = np.searchsorted(cumw, 0.90) + 1
print(f"{n50} trajs (~{n50/len(W)*100:.2f}%) cover 50% of total weight")
print(f"{n90} trajs (~{n90/len(W)*100:.2f}%) cover 90% of total weight")

# 3) WIS vs Behavior

plt.figure(figsize=(5,4))
plt.bar([0,1], [behavior, wis], color=['#7f8c8d','#2b8cbe'])
plt.errorbar([1], [wis], yerr=[[wis-ci_low],[ci_high-wis]], fmt='none', capsize=8, color='k')
plt.xticks([0,1], ["Behavior", "Target Policy"])
plt.ylabel("Estimated Discounted Return")
plt.title("WIS vs Behavior")
plt.grid(axis='y', alpha=0.3)
# annotate significance note
if ci_low > behavior:
    plt.text(0.5, max(wis, behavior)+0.2, "95% CI > behavior → significant", ha='center', color='g')
else:
    plt.text(0.5, max(wis, behavior)+0.2, "CI overlaps behavior → not significant at 95%", ha='center', color='orange')
plt.show()

# 4) Top-weighted trajectories table

df_top = pd.DataFrame({
    "traj_key": list(seq_dedup.keys()),
    "weight": W,
    "disc_return": R
}).sort_values("weight", ascending=False).head(10).reset_index(drop=True)
display(df_top)

# Bootstrap p-value: proportion of bootstrap WIS samples ≤ behavior (one-sided)
B = 2000
rng = np.random.default_rng(123)
n = len(W)
bs_vals = np.empty(B)
for i in range(B):
    idx = rng.integers(0, n, n)
    w_s = W[idx]; r_s = R[idx]
    bs_vals[i] = (w_s * r_s).sum() / (w_s.sum() + 1e-12)

# p-value (one-sided: how often WIS <= behavior)
p_one_sided = np.mean(bs_vals <= behavior)
# two-sided: how often abs(diff) >= observed abs diff
obs_diff = wis - behavior
p_two_sided = np.mean(np.abs(bs_vals - behavior) >= abs(obs_diff))

print("Observed WIS - behavior = %.4f" % obs_diff)
print("One-sided p (WIS <= behavior):", p_one_sided)
print("Two-sided p:", p_two_sided)

# plot bootstrap density
plt.figure(figsize=(6,3))
k = gaussian_kde(bs_vals)
xs = np.linspace(min(bs_vals), max(bs_vals), 200)
plt.plot(xs, k(xs))
plt.axvline(behavior, color='C1', linestyle='--', label='behavior')
plt.axvline(wis, color='C2', linestyle='-', label='WIS')
plt.legend()
plt.title("Bootstrap distribution of WIS (deduped)")
plt.show()

N = 5
top_keys = df_top['traj_key'].tolist()[:N]
for k in top_keys:
    print("=== traj", k, "===")
    seq = seq_dedup[eval(k)] if isinstance(k, str) else seq_dedup[k]
    print("len:", len(seq['A']))
    print("A:", seq['A'])
    print("R:", seq['R'])
    s_df = pd.DataFrame(seq['S'], columns=state_cols)
    display(s_df)